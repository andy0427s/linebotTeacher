{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Azure Pronunciation Accessment for wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Creates an instance of a speech config with specified subscription key and service region.\n",
    "# Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "speech_key, service_region = \"b8a6c86042ea49df86d9b0ead79eff31\", \"southcentralus\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "\n",
    "# pronunciation_assessment_config = \\\n",
    "#         speechsdk.PronunciationAssessmentConfig(reference_text='hello world',\n",
    "#                 grading_system=msspeech.PronunciationAssessmentGradingSystem.HundredMark,\n",
    "#                 granularity=msspeech.PronunciationAssessmentGranularity.Phoneme)\n",
    "# speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "#         speech_config=speech_config, \\\n",
    "#         audio_config=audio_config)\n",
    "\n",
    "# # apply the pronunciation assessment configuration to the speech recognizer\n",
    "# pronunciation_assessment_config.apply_to(speech_recognizer)\n",
    "# result = speech_recognizer.recognize_once()\n",
    "# pronunciation_assessment_result = speechsdk.PronunciationAssessmentResult(result)\n",
    "# pronunciation_score = pronunciation_assessment_result.pronunciation_score\n",
    "\n",
    "\n",
    "# a common wave header, with zero audio length\n",
    "# since stream data doesn't contain header, but the API requires header to fetch format information, so you need post this header as first chunk for each query\n",
    "WaveHeader16K16BitMono = bytes([ 82, 73, 70, 70, 78, 128, 0, 0, 87, 65, 86, 69, 102, 109, 116, 32, 18, 0, 0, 0, 1, 0, 1, 0, 128, 62, 0, 0, 0, 125, 0, 0, 2, 0, 16, 0, 0, 0, 100, 97, 116, 97, 0, 0, 0, 0 ])\n",
    "\n",
    "def get_chunk(audio_source, chunk_size=1024):\n",
    "  yield WaveHeader16K16BitMono\n",
    "  while True:\n",
    "    time.sleep(chunk_size / 32000) # to simulate human speaking rate\n",
    "    chunk = audio_source.read(chunk_size)\n",
    "    if not chunk:\n",
    "      global uploadFinishTime\n",
    "      uploadFinishTime = time.time()\n",
    "      break\n",
    "    yield chunk\n",
    "\n",
    "referenceText = 'Hello World'    \n",
    "pronAssessmentParamsJson = \"{\\\"ReferenceText\\\":\\\"%s\\\",\\\"GradingSystem\\\":\\\"HundredMark\\\",\\\"Dimension\\\":\\\"Comprehensive\\\"}\" % referenceText\n",
    "pronAssessmentParamsBase64 = base64.b64encode(bytes(pronAssessmentParamsJson, 'utf-8'))\n",
    "pronAssessmentParams = str(pronAssessmentParamsBase64, \"utf-8\")\n",
    "\n",
    "\n",
    "# build request\n",
    "url = \"https://southcentralus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=en-us\" \n",
    "headers = { 'Accept': 'application/json;text/xml',\n",
    "            'Connection': 'Keep-Alive',\n",
    "            'Content-Type': 'audio/wav; codecs=audio/pcm; samplerate=16000',\n",
    "            'Ocp-Apim-Subscription-Key': speech_key,\n",
    "            'Pronunciation-Assessment': pronAssessmentParams,\n",
    "            'Transfer-Encoding': 'chunked',\n",
    "            'Expect': '100-continue' }\n",
    "\n",
    "\n",
    "audioFile = open('./helloworld.wav', 'rb')\n",
    "\n",
    "\n",
    "response = requests.post(url=url, data=get_chunk(audioFile), headers=headers)\n",
    "getResponseTime = time.time()\n",
    "audioFile.close()\n",
    "\n",
    "resultJson = json.loads(response.text)\n",
    "print(json.dumps(resultJson, indent=4))\n",
    "\n",
    "latency = getResponseTime - uploadFinishTime\n",
    "print(\"Latency = %sms\" % int(latency * 1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-bad23ee3d715>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-bad23ee3d715>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    questions = string(list(range(1:101)))\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "questions = string(list(range(100)))\n",
    "print(questions)\n",
    "\n",
    "\n",
    "print(\"_\"*20)\n",
    "text = input()\n",
    "\n",
    "\n",
    "mark = int(text)\n",
    "\n",
    "print(\"_\"*20)\n",
    "\n",
    "if mark in questions:\n",
    "    print(f\"確認題目編號，請開始錄音!\\n或輸入'back'返回主選單\")\n",
    "\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(f\"無此題目編號，請重新輸入assignID\\n或輸入'back'返回主選單\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
