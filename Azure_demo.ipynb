{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行語音轉文字服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Creates an instance of a speech config with specified subscription key and service region.\n",
    "# Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "speech_key, service_region = \"196f2f318dc744049eafb9cf89631e42\", \"southcentralus\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "# Creates an audio configuration that points to an audio file.\n",
    "# Replace with your own audio filename.\n",
    "audio_filename = \"narration.wav\"\n",
    "audio_input = speechsdk.audio.AudioConfig(filename=audio_filename)\n",
    "\n",
    "# Creates a recognizer with the given settings\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
    "\n",
    "print(\"Recognizing first result...\")\n",
    "\n",
    "# Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "# single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "# seconds of audio is processed.  The task returns the recognition text as result. \n",
    "# Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "# shot recognition like command or query. \n",
    "# For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "result = speech_recognizer.recognize_once()\n",
    "\n",
    "# Checks result.\n",
    "if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "    print(\"Recognized: {}\".format(result.text))\n",
    "elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "    print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行文字轉語音服務操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字轉成合成語音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Creates an instance of a speech config with specified subscription key and service region.\n",
    "# Replace with your own subscription key and service region (e.g., \"westus\").\n",
    "speech_key, service_region = \"196f2f318dc744049eafb9cf89631e42\", \"southcentralus\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "# Creates a speech synthesizer using the default speaker as audio output.\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "# Receives a text from console input.\n",
    "print(\"Type some text that you want to speak...\")\n",
    "text = input()\n",
    "\n",
    "# Synthesizes the received text to speech.\n",
    "# The synthesized speech is expected to be heard on the speaker with this line executed.\n",
    "result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "# Checks result.\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized to speaker for text [{}]\".format(text))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    print(\"Did you update the subscription info?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字轉成音訊檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "# Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "speech_key, service_region = \"196f2f318dc744049eafb9cf89631e42\", \"southcentralus\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "# Creates an audio configuration that points to an audio file.\n",
    "# Replace with your own audio filename.\n",
    "audio_filename = \"helloworld.wav\"\n",
    "audio_output = speechsdk.audio.AudioOutputConfig(filename=audio_filename)\n",
    "\n",
    "# Creates a synthesizer with the given settings\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "# Synthesizes the text to speech.\n",
    "# Replace with your own text.\n",
    "text = \"Hello world!\"\n",
    "result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "# Checks result.\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized to [{}] for text [{}]\".format(audio_filename, text))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "    print(\"Did you update the subscription info?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 語音轉成翻譯文字服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "speech_key, service_region = \"196f2f318dc744049eafb9cf89631e42\", \"southcentralus\"\n",
    "\n",
    "def translate_speech_to_text():\n",
    "\n",
    "    # Creates an instance of a speech translation config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "    translation_config = speechsdk.translation.SpeechTranslationConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Sets source and target languages.\n",
    "    # Replace with the languages of your choice, from list found here: https://aka.ms/speech/sttt-languages\n",
    "    fromLanguage = 'en-US'\n",
    "    toLanguage = 'de'      #找 文本語言 line 33底下也需要更改\n",
    "    translation_config.speech_recognition_language = fromLanguage\n",
    "    translation_config.add_target_language(toLanguage)\n",
    "\n",
    "    # Creates a translation recognizer using and audio file as input.\n",
    "    recognizer = speechsdk.translation.TranslationRecognizer(translation_config=translation_config)\n",
    "\n",
    "    # Starts translation, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognized text as well as the translation.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    print(\"Say something...\")\n",
    "    result = recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.TranslatedSpeech:\n",
    "        print(\"RECOGNIZED '{}': {}\".format(fromLanguage, result.text))\n",
    "        print(\"TRANSLATED into {}: {}\".format(toLanguage, result.translations['de']))\n",
    "    elif result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"RECOGNIZED: {} (text could not be translated)\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"NOMATCH: Speech could not be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        print(\"CANCELED: Reason={}\".format(result.cancellation_details.reason))\n",
    "        if result.cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"CANCELED: ErrorDetails={}\".format(result.cancellation_details.error_details))\n",
    "\n",
    "translate_speech_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 語音轉成多國翻譯文字服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "speech_key, service_region = \"196f2f318dc744049eafb9cf89631e42\", \"southcentralus\"\n",
    "\n",
    "def translate_speech_to_text():\n",
    "\n",
    "    # Creates an instance of a speech translation config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "    translation_config = speechsdk.translation.SpeechTranslationConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Sets source and target languages.\n",
    "    # Replace with the languages of your choice, from list found here: https://aka.ms/speech/sttt-languages\n",
    "    fromLanguage = 'en-US'\n",
    "    translation_config.speech_recognition_language = fromLanguage\n",
    "    translation_config.add_target_language('de')\n",
    "    translation_config.add_target_language('fr')\n",
    "\n",
    "    # Creates a translation recognizer using and audio file as input.\n",
    "    recognizer = speechsdk.translation.TranslationRecognizer(translation_config=translation_config)\n",
    "\n",
    "    # Starts translation, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognized text as well as the translation.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    print(\"Say something...\")\n",
    "    result = recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.TranslatedSpeech:\n",
    "        print(\"RECOGNIZED '{}': {}\".format(fromLanguage, result.text))\n",
    "        print(\"TRANSLATED into {}: {}\".format('de', result.translations['de']))\n",
    "        print(\"TRANSLATED into {}: {}\".format('fr', result.translations['fr']))\n",
    "    elif result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"RECOGNIZED: {} (text could not be translated)\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"NOMATCH: Speech could not be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        print(\"CANCELED: Reason={}\".format(result.cancellation_details.reason))\n",
    "        if result.cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"CANCELED: ErrorDetails={}\".format(result.cancellation_details.error_details))\n",
    "\n",
    "translate_speech_to_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 語音轉成多國語音服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "speech_key, service_region = \"196f2f318dc744049eafb9cf89631e42\", \"southcentralus\"\n",
    "\n",
    "def translate_speech_to_speech():\n",
    "\n",
    "    # Creates an instance of a speech translation config with specified subscription key and service region.\n",
    "    # Replace with your own subscription key and region identifier from here: https://aka.ms/speech/sdkregion\n",
    "    translation_config = speechsdk.translation.SpeechTranslationConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "    # Sets source and target languages.\n",
    "    # Replace with the languages of your choice, from list found here: https://aka.ms/speech/sttt-languages\n",
    "    fromLanguage = 'en-US'\n",
    "    toLanguage = 'de'\n",
    "    translation_config.speech_recognition_language = fromLanguage\n",
    "    translation_config.add_target_language(toLanguage)\n",
    "\n",
    "    # Sets the synthesis output voice name.\n",
    "    # Replace with the languages of your choice, from list found here: https://aka.ms/speech/tts-languages\n",
    "    translation_config.voice_name = \"de-DE-Hedda\"\n",
    "\n",
    "    # Creates a translation recognizer using and audio file as input.\n",
    "    recognizer = speechsdk.translation.TranslationRecognizer(translation_config=translation_config)\n",
    "\n",
    "    # Prepare to handle the synthesized audio data.\n",
    "    def synthesis_callback(evt):\n",
    "        size = len(evt.result.audio)\n",
    "        print('AUDIO SYNTHESIZED: {} byte(s) {}'.format(size, '(COMPLETED)' if size == 0 else ''))\n",
    "\n",
    "    recognizer.synthesizing.connect(synthesis_callback)\n",
    "\n",
    "    # Starts translation, and returns after a single utterance is recognized. The end of a\n",
    "    # single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "    # seconds of audio is processed. It returns the recognized text as well as the translation.\n",
    "    # Note: Since recognize_once() returns only a single utterance, it is suitable only for single\n",
    "    # shot recognition like command or query.\n",
    "    # For long-running multi-utterance recognition, use start_continuous_recognition() instead.\n",
    "    print(\"Say something...\")\n",
    "    result = recognizer.recognize_once()\n",
    "\n",
    "    # Check the result\n",
    "    if result.reason == speechsdk.ResultReason.TranslatedSpeech:\n",
    "        print(\"RECOGNIZED '{}': {}\".format(fromLanguage, result.text))\n",
    "        print(\"TRANSLATED into {}: {}\".format(toLanguage, result.translations['de']))\n",
    "    elif result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"RECOGNIZED: {} (text could not be translated)\".format(result.text))\n",
    "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"NOMATCH: Speech could not be recognized: {}\".format(result.no_match_details))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        print(\"CANCELED: Reason={}\".format(result.cancellation_details.reason))\n",
    "        if result.cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"CANCELED: ErrorDetails={}\".format(result.cancellation_details.error_details))\n",
    "\n",
    "translate_speech_to_speech()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文字語言偵測服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "\n",
    "key = \"bdb7d45b308f4851bd1b8cae9a1d3453\"\n",
    "endpoint = \"https://test0524.cognitiveservices.azure.com/\"\n",
    "\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "documents = [\n",
    "    \"This document is written in English.\",\n",
    "    \"Este es un document escrito en Español.\",\n",
    "    \"这是一个用中文写的文件\",\n",
    "    \"Dies ist ein Dokument in deutsche Sprache.\",\n",
    "    \"Detta är ett dokument skrivet på engelska.\"\n",
    "]\n",
    "\n",
    "result = text_analytics_client.detect_language(documents)\n",
    "\n",
    "for idx, doc in enumerate(result):\n",
    "    if not doc.is_error:\n",
    "        print(\"Document text: {}\".format(documents[idx]))\n",
    "        print(\"Language detected: {}\".format(doc.primary_language.name))\n",
    "        print(\"ISO6391 name: {}\".format(doc.primary_language.iso6391_name))\n",
    "        print(\"Confidence score: {}\\n\".format(doc.primary_language.confidence_score))\n",
    "    if doc.is_error:\n",
    "        print(doc.id, doc.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行關鍵字詞擷取服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "key = \"bdb7d45b308f4851bd1b8cae9a1d3453\"\n",
    "endpoint = \"https://test0524.cognitiveservices.azure.com/\"\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "documents = [\n",
    "    \"Redmond is a city in King County, Washington, United States, located 15 miles east of Seattle.\",\n",
    "    \"I need to take my cat to the veterinarian.\",\n",
    "    \"I will travel to South America in the summer.\",\n",
    "]\n",
    "\n",
    "result = text_analytics_client.extract_key_phrases(documents)\n",
    "for doc in result:\n",
    "    if not doc.is_error:\n",
    "        print(doc.key_phrases)\n",
    "    if doc.is_error:\n",
    "        print(doc.id, doc.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行實體辨識服務操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實體辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "key = \"bdb7d45b308f4851bd1b8cae9a1d3453\"\n",
    "endpoint = \"https://test0524.cognitiveservices.azure.com/\"\n",
    "\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "documents = [\n",
    "    \"Microsoft was founded by Bill Gates and Paul Allen.\",\n",
    "    \"I had a wonderful trip to Seattle last week.\",\n",
    "    \"I visited the Space Needle 2 times.\",\n",
    "]\n",
    "\n",
    "result = text_analytics_client.recognize_entities(documents)\n",
    "docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(\"\\nDocument text: {}\".format(documents[idx]))\n",
    "    for entity in doc.entities:\n",
    "        print(\"Entity: \\t\", entity.text, \"\\tCategory: \\t\", entity.category,\n",
    "              \"\\tConfidence Score: \\t\", entity.confidence_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實體連結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "key = \"bdb7d45b308f4851bd1b8cae9a1d3453\"\n",
    "endpoint = \"https://test0524.cognitiveservices.azure.com/\"\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "documents = [\n",
    "    \"Microsoft moved its headquarters to Bellevue, Washington in January 1979.\",\n",
    "    \"Steve Ballmer stepped down as CEO of Microsoft and was succeeded by Satya Nadella.\",\n",
    "    \"Microsoft superó a Apple Inc. como la compañía más valiosa que cotiza en bolsa en el mundo.\",\n",
    "]\n",
    "\n",
    "result = text_analytics_client.recognize_linked_entities(documents)\n",
    "docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(\"Document text: {}\\n\".format(documents[idx]))\n",
    "    for entity in doc.entities:\n",
    "        print(\"Entity: {}\".format(entity.name))\n",
    "        print(\"Url: {}\".format(entity.url))\n",
    "        print(\"Data Source: {}\".format(entity.data_source))\n",
    "        for match in entity.matches:\n",
    "            print(\"Confidence Score: {}\".format(match.confidence_score))\n",
    "            print(\"Entity as appears in request: {}\".format(match.text))\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行文本翻譯服務操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, requests, uuid, json\n",
    "\n",
    "subscription_key = 'ab93f8c61e174973818ac06706a5a5d5' # your key\n",
    "endpoint = 'https://api.cognitive.microsofttranslator.com/'\n",
    "\n",
    "# key_var_name = 'TRANSLATOR_TEXT_SUBSCRIPTION_KEY'\n",
    "# if not key_var_name in os.environ:\n",
    "#     raise Exception('Please set/export the environment variable: {}'.format(key_var_name))\n",
    "# subscription_key = os.environ[key_var_name]\n",
    "\n",
    "# endpoint_var_name = 'TRANSLATOR_TEXT_ENDPOINT'\n",
    "# if not endpoint_var_name in os.environ:\n",
    "#     raise Exception('Please set/export the environment variable: {}'.format(endpoint_var_name))\n",
    "# endpoint = os.environ[endpoint_var_name]\n",
    "\n",
    "path = '/translate?api-version=3.0'\n",
    "\n",
    "# Output language setting\n",
    "params = '&to=de&to=it'\n",
    "constructed_url = endpoint + path + params\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "    'Content-type': 'application/json',\n",
    "    'X-ClientTraceId': str(uuid.uuid4())\n",
    "}\n",
    "\n",
    "body = [{\n",
    "    'text': 'Hello World!'\n",
    "}]\n",
    "\n",
    "request = requests.post(constructed_url, headers=headers, json=body)\n",
    "response = request.json()\n",
    "\n",
    "print(json.dumps(response, sort_keys=True, indent=4,\n",
    "                 ensure_ascii=False, separators=(',', ': ')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 執行LUIS意圖辨識服務操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "\n",
    "    key = '8286e59fe6f54ab9826222300bbdcb11' # your Runtime key\n",
    "    endpoint = 'westus.api.cognitive.microsoft.com' # such as 'your-resource-name.api.cognitive.microsoft.com'\n",
    "    appId = 'df67dcdb-c37d-46af-88e1-8b97951ca1c2'\n",
    "    utterance = 'turn on all lights'\n",
    "\n",
    "    headers = {\n",
    "    }\n",
    "\n",
    "    params ={\n",
    "        'query': utterance,\n",
    "        'timezoneOffset': '0',\n",
    "        'verbose': 'true',\n",
    "        'show-all-intents': 'true',\n",
    "        'spellCheck': 'false',\n",
    "        'staging': 'false',\n",
    "        'subscription-key': key\n",
    "    }\n",
    "\n",
    "    r = requests.get(f'https://{endpoint}/luis/prediction/v3.0/apps/{appId}/slots/production/predict',headers=headers, params=params)\n",
    "    print(r.json())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'{e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.language.luis.runtime import LUISRuntimeClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "import datetime, json, os, time\n",
    "\n",
    "# Use public app ID or replace with your own trained and published app's ID\n",
    "# to query your own app\n",
    "# public appID = 'df67dcdb-c37d-46af-88e1-8b97951ca1c2'\n",
    "luisAppID = 'dcb2cb33-dee6-46c1-a3a6-28e266d159e0'\n",
    "runtime_key = '8286e59fe6f54ab9826222300bbdcb11'\n",
    "runtime_endpoint = 'https://westus.api.cognitive.microsoft.com/'\n",
    "\n",
    "# production or staging\n",
    "luisSlotName = 'production'\n",
    "\n",
    "# Instantiate a LUIS runtime client\n",
    "clientRuntime = LUISRuntimeClient(runtime_endpoint, CognitiveServicesCredentials(runtime_key))\n",
    "\n",
    "def predict(app_id, slot_name):\n",
    "\n",
    "    request = { \"query\" : \"hi, show me lovely baby pictures\" }\n",
    "\n",
    "    # Note be sure to specify, using the slot_name parameter, whether your application is in staging or \\\n",
    "    # production.\n",
    "    response = clientRuntime.prediction.get_slot_prediction(app_id=app_id, slot_name=slot_name, \\\n",
    "                                                            prediction_request=request)\n",
    "\n",
    "    print(\"Top intent: {}\".format(response.prediction.top_intent))\n",
    "    print(\"Sentiment: {}\".format (response.prediction.sentiment))\n",
    "    print(\"Intents: \")\n",
    "\n",
    "    for intent in response.prediction.intents:\n",
    "        print(\"\\t{}\".format (json.dumps (intent)))\n",
    "    print(\"Entities: {}\".format (response.prediction.entities))\n",
    "    \n",
    "predict(luisAppID, luisSlotName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
